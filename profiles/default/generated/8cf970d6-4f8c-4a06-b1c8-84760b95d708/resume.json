{
    "work": [
        {
            "company": "Amazon",
            "position": "Data Engineer 2",
            "startDate": "06/2021",
            "endDate": "Present",
            "location": "Seattle, WA",
            "highlights": [
                "Led the migration of 700 data pipelines, achieving cost savings through improved efficiency and optimization, demonstrating ability to develop unconventional solutions.",
                "Automated quarterly ingestion of 11M+ records by building end-to-end vendor data pipelines using Airflow, **Spark**, ensuring timely availability for candidate targeting.",
                "Architected a unified data foundation using Step Functions, Spark, and **Iceberg**, enabling schema evolution and metadata-driven governance for the entire owned channel ecosystem.",
                "Achieved a 3.5x performance boost and 50% cost reduction by optimizing worker usage and migrating to efficient storage formats (**Parquet**), demonstrating ETL optimization.",
                "Defined and implemented **data classification standards** and enforced Zero Trust access controls using Lake Formation and IAM, emphasizing **data security** and compliance."
            ],
            "website": ""
        },
        {
            "company": "Amazon",
            "position": "Software Development Engineer",
            "startDate": "08/2020",
            "endDate": "06/2021",
            "location": "Seattle, WA",
            "highlights": [
                "Utilized a suite of technologies including Java, Redshift, S3, Fargate, and Quicksight to craft dynamic Amazon detail page dashboards, facilitating comprehensive insights into product performance.",
                "Spearheaded the development of a machine learning-driven recommendation system aimed at augmenting the customer experience, leveraging data-driven insights.",
                "Engineered ETL processes that fed analytical platforms, maintaining **data quality** and timeliness for downstream reporting.",
                "Managed large databases and executed complex data profiling tasks supporting marketing science initiatives.",
                "Demonstrated proficiency with Linux command line in managing environment configurations for data processing jobs."
            ],
            "website": ""
        },
        {
            "company": "Arkadium",
            "position": "Data Science Intern",
            "startDate": "05/2019",
            "endDate": "05/2020",
            "location": "New York City, NY",
            "highlights": [
                "Identified factors contributing to critical game errors using Root Cause Analysis, thus improving customer retention of online games.",
                "Leveraged Microsoft Azure Data Lake and **Python** to conduct Error Cluster Analysis for a dataset comprising 4 million instances.",
                "**Profiled** large datasets to identify anomalies and insights related to user behavior and game performance.",
                "Visualized KPIs like visits, revenue and CTR with **Power BI Dashboard** to assess growth and stability of the organization.",
                "Gained initial exposure to distributed systems concepts while analyzing large-scale telemetry data."
            ],
            "website": ""
        },
        {
            "company": "Accenture Financial Services",
            "position": "Application Development Associate",
            "startDate": "11/2016",
            "endDate": "07/2018",
            "location": "India",
            "highlights": [
                "Spearheaded the development of core Extract, Transform, Load (ETL) functionalities catering to a leading Swiss bank client operating in the Credit Risk IT domain, leveraging Java and **PL/SQL**.",
                "Engineered and implemented a Blocking Queue within a multithreaded framework, resulting in a remarkable 75% increase in the system's load capacity.",
                "Applied complex **data modelling** principles during ETL design, ensuring data integrity for financial reporting.",
                "Maintained and optimized existing analytical data structures, ensuring **timeliness** for business consumption.",
                "Collaborated with team members using version control for concurrent development and code review processes."
            ],
            "website": ""
        }
    ],
    "skills": [
        {
            "name": "Programming Languages",
            "keywords": [
                "Python, Apache Spark, Java, SQL, Ruby, Linux"
            ],
            "level": ""
        },
        {
            "name": "Data Engineering & ETL",
            "keywords": [
                "Apache Spark (Performance Tuning), Airflow, DBT, ETL Optimization, Kafka/Streaming, AWS Glue"
            ],
            "level": ""
        },
        {
            "name": "Cloud & Infrastructure",
            "keywords": [
                "AWS (S3, Lake Formation, IAM), Distributed Systems, Linux command line, MPP"
            ],
            "level": ""
        },
        {
            "name": "Data Storage & Warehousing",
            "keywords": [
                "Data Warehousing Concepts, Hive, Redshift, Iceberg, Parquet, Data Modelling, Partitioning"
            ],
            "level": ""
        },
        {
            "name": "Analytics & Business Alignment",
            "keywords": [
                "KPI Validation, Data Profiling, Statistical Analysis, Data Lineage Tracking, BI Platform Support"
            ],
            "level": ""
        },
        {
            "name": "Data Governance & Security",
            "keywords": [
                "Data Quality, Data Security, Schema Evolution, Data Discoverability"
            ],
            "level": ""
        },
        {
            "name": "Methodologies",
            "keywords": [
                "Operational Excellence, Lambda Architecture, Batch/Stream Processing, Unconventional Solution Development"
            ],
            "level": ""
        }
    ],
    "professional_summary": "Data Engineer with 6+ years of experience building scalable data ecosystems and **analytics platforms** at Amazon, specializing in **ETL optimization**, **data quality**, and modern cloud architectures. Expert in **Apache Spark**, **SQL optimization**, AWS services (Glue, Redshift, Lake Formation), and **Big Data technologies** like Hive. Proven track record in designing low latency data architectures, enhancing **data discoverability**, and leveraging data to fuel smarter decisions and personalized customer experiences.",
    "basics": {
        "name": "Satyen Amonkar",
        "email": "95satyen@gmail.com",
        "phone": "3154034538",
        "location": {
            "address": "Seattle, Washington"
        }
    },
    "education": []
}