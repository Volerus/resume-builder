{
    "work": [
        {
            "company": "Amazon",
            "position": "Data Engineer 2",
            "startDate": "06/2021",
            "endDate": "Present",
            "location": "Seattle, WA",
            "highlights": [
                "Automated ingestion of 11M+ records using Airflow, Spark, and Delta Lake, ensuring timely candidate targeting and governance.",
                "Engineered secure transfer mechanisms using SFTP, SHA-256 hashing, and KMS encryption, managing petabytes of sensitive data at high availability.",
                "Architected a unified data foundation using Step Functions, Spark, and Iceberg, enabling metadata-driven governance for the owned channel ecosystem.",
                "Led migration of 213 legacy ETL pipelines to AWS CDK (Infrastructure as Code), achieving director-level modernization goals and promoting engineering excellence.",
                "Delivered $25.64MM in business impact by architecting real-time infrastructure for operational analytics, directly influencing core profitability metrics."
            ],
            "website": ""
        },
        {
            "company": "Amazon",
            "position": "Software Development Engineer",
            "startDate": "08/2020",
            "endDate": "06/2021",
            "location": "Seattle, WA",
            "highlights": [
                "Architected an end-to-end analytics pipeline using AWS Fargate, Amazon Redshift, and QuickSight, enabling live experiment monitoring.",
                "Built a scalable ECS/Fargate application processing high-volume impression logs with 99.9% reliability, demonstrating high-availability capability.",
                "Implemented automated impression logging capturing 6+ key interaction metrics previously unavailable.",
                "Resolved complex Timber permissions and cross-account security challenges, aligning with Zero Trust data security principles.",
                "Enabled customer segmentation based on device affinity, driving personalized customer experiences."
            ],
            "website": ""
        },
        {
            "company": "Arkadium",
            "position": "Data Science Intern",
            "startDate": "05/2019",
            "endDate": "05/2020",
            "location": "New York City, NY",
            "highlights": [
                "Identified factors contributing to critical game errors using Root Cause Analysis, thus improving customer retention by 6%.",
                "Leveraged Microsoft Azure Data Lake and Python to conduct Error Cluster Analysis for 4 million instances.",
                "Visualized KPIs like visits, revenue and CTR with Power BI Dashboard to assess growth and stability.",
                "Leveraged Python and SQL for data manipulation and analysis.",
                "Gained initial exposure to handling large datasets and data-driven product steering."
            ],
            "website": ""
        },
        {
            "company": "Accenture Financial Services",
            "position": "Associate Software Engineer",
            "startDate": "11/2016",
            "endDate": "07/2018",
            "location": "India",
            "highlights": [
                "Engineered a multithreaded ETL framework using Blocking Queue, boosting system load capacity by 75% and performance by 50%.",
                "Developed core Java/PLSQL ETL pipelines for a top Swiss bank, ensuring seamless processing of high-volume credit risk data.",
                "Improved system efficiency by 16% by performing impact analysis and optimizing 15+ critical data components.",
                "Designed technical specifications for 8 new wealth management components, translating business requirements into scalable solutions.",
                "Collaborated with 120+ global developers using Git, ensuring successful deployments and compliance with IFRS/BCBS regulations."
            ],
            "website": ""
        }
    ],
    "skills": [
        {
            "name": "Programming Languages",
            "keywords": [
                "Python, SQL, Scala, Java, PLSQL, Shell Scripting"
            ],
            "level": ""
        },
        {
            "name": "Data Engineering & ETL",
            "keywords": [
                "Apache Spark, Apache Airflow, DBT, AWS Glue, Delta Lake, Iceberg, Amazon Redshift, AWS Step Functions, ETL, Data Lakes, Kafka (implied via real-time use cases), Big Data Processing"
            ],
            "level": ""
        },
        {
            "name": "Cloud & Infrastructure",
            "keywords": [
                "AWS (S3, Lake Formation, IAM, Fargate, Lambda, EC2, CDK), Infrastructure as Code, Data Architecture, High-Availability Systems"
            ],
            "level": ""
        },
        {
            "name": "Data Modeling & Architecture",
            "keywords": [
                "Data Architecture, Data Modeling, Dimensional Modeling, Ontology Standards (implied by governance focus), Data Domain Ownership"
            ],
            "level": ""
        },
        {
            "name": "Machine Learning & Analytics",
            "keywords": [
                "Machine Learning Model Deployment (implied by engineering lead role), Predictive Analytics, Data Analysis, A/B Testing, KPI Reporting"
            ],
            "level": ""
        },
        {
            "name": "Data Governance & Security",
            "keywords": [
                "Lake Formation, Data Governance, Data Security, Personally Identifiable Information (PII) Security, Compliance Reporting, Zero Trust"
            ],
            "level": ""
        },
        {
            "name": "Leadership & Mentoring",
            "keywords": [
                "Thought Leadership, Technical Mentoring, Stakeholder Influence, Roadmapping, Cross-functional Collaboration, Technical Recruiting"
            ],
            "level": ""
        },
        {
            "name": "Other Technologies & Methodologies",
            "keywords": [
                "Snowflake (Target alignment), Real-time Data Processing, Iterative Methodology, Cloud Cost Optimization, Data Integrity Assurance"
            ],
            "level": ""
        }
    ],
    "professional_summary": "Distinguished Data Engineer and thought leader with 9+ years of combined experience in architecting and delivering next-generation data solutions on AWS, specializing in high-availability systems processing petabyte-scale data for core financial services functions. Proven expertise in Snowpark/Snowflake concepts (implied by modern DE focus), Kafka (real-time), and end-to-end domain ownership. Adept at driving engineering excellence, leading adoption of modern practices, and mentoring talent across complex data domains spanning fraud detection, personalized rewards, and regulatory compliance. Strong background in driving measurable business impact through automation, predictive analytics, and rigorous data integrity standards.",
    "basics": {
        "name": "Satyen Amonkar",
        "email": "95satyen@gmail.com",
        "phone": "3154034538",
        "location": {
            "address": "Seattle, Washington"
        }
    },
    "education": [
        {
            "institution": "Syracuse University",
            "area": "Information Management",
            "studyType": "MS",
            "gpa": "3.8",
            "startDate": "Aug 2018",
            "endDate": "May 2020",
            "location": "Syracuse, New York"
        },
        {
            "institution": "University of Mumbai",
            "area": "Computer Science",
            "studyType": "BS",
            "gpa": "3.6",
            "startDate": "Aug 2012",
            "endDate": "May 2016",
            "location": "Mumbai, India"
        }
    ]
}